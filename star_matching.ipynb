{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass()\n",
    "class Star:\n",
    "  name: str\n",
    "  position: np.ndarray\n",
    "  \n",
    "def read_Star_data(star_file):\n",
    "  star_data = pd.read_csv(star_file,header=None)\n",
    "  star = []\n",
    "  star_name_list = []\n",
    "  for _ in star_data.iterrows():\n",
    "    if _[0]%3 == 0:\n",
    "      starname = _[1][1].rsplit('-',maxsplit=1)[0].replace(' ','')\n",
    "      star_name_list.append(starname)\n",
    "    if _[0]%3 == 1:\n",
    "      star_temp = Star(name=starname, position=np.array([_[1][1], _[1][2], _[1][3]]).astype(np.float64))\n",
    "      star.append(star_temp)\n",
    "  return star, star_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass()\n",
    "class Sensor:\n",
    "  time: pd.Timestamp\n",
    "  q: np.ndarray\n",
    "  position_a: np.ndarray\n",
    "  position: np.ndarray\n",
    "\n",
    "def read_sensor_data(sensor_file):\n",
    "  sensor_data = pd.read_csv(sensor_file)\n",
    "  sensor = []\n",
    "  sensor_data['Time (UTCG)'] = pd.to_datetime(sensor_data['Time (UTCG)'])\n",
    "  time_ls = sensor_data['Time (UTCG)'].tolist()\n",
    "  for index, row in sensor_data.iterrows():\n",
    "    sensor.append(Sensor(\n",
    "      time = row[0],\n",
    "      q = row[7:11].to_numpy(dtype=np.float64),\n",
    "      position_a = row[1:4].to_numpy(dtype=np.float64),\n",
    "      position = np.zeros(3)\n",
    "    ))\n",
    "  return sensor,time_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_uv = pd.read_csv('star_data.csv')\n",
    "# sensor_attitude = pd.read_csv('data/sensor_attitude.csv')\n",
    "sensor, time_ls = read_sensor_data('data/mysenior_sensor_data_output.csv')\n",
    "star, star_name_list = read_Star_data('data/reduced_star.csv')\n",
    "time_list = star_uv['time'].tolist()\n",
    "star_uv['time'] = pd.to_datetime(star_uv['time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StarMatch:\n",
    "  def __init__(self, name, index, u, v):\n",
    "    self.name = name\n",
    "    self.index = index\n",
    "    self.u = u\n",
    "    self.v = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def star_match(uv_dict, star_data, sensor_q, sensor_pos_est):\n",
    "  #参数：uv_dict:字典，键为编号，值为uv值  debris_dict:字典，键为编号，值为debris名字str  debris_data:所有debris在此刻的对象，长度为debris的数目  sensor_q:传感器姿态数据  sensor_pos_est:传感器位置数据，预估，有误差\n",
    "  #返回：debris_dict:字典，键为编号，值为debris名字str；error,当匹配失败时，返回一个误差\n",
    "  f = 0.01413\n",
    "  dh = 0.000006\n",
    "  dv = 0.000006\n",
    "  H = 700\n",
    "  star_dict = {}\n",
    "  if sensor_q[3] < 0:\n",
    "    sensor_q = -sensor_q\n",
    "  q0, q1, q2, q3 = sensor_q\n",
    "  Msi = np.array([[q3**2+q0**2-q1**2-q2**2, 2*q3*q2+2*q0*q1,     -2*q3*q1+2*q0*q2],\n",
    "                    [-2*q3*q2+2*q0*q1,    q3**2-q0**2+q1**2-q2**2, 2*q3*q0+2*q1*q2],\n",
    "                    [2*q3*q1+2*q0*q2,     -2*q3*q0+2*q1*q2,    q3**2-q0**2-q1**2+q2**2]])\n",
    "  match_ls = [] #存放计算的可能的目标碎片，目前只有碎片名称但没有碎片编号\n",
    "  for star0 in star_data:\n",
    "    name = star0.name\n",
    "    vec = star0.position\n",
    "    A = np.dot(Msi, vec)\n",
    "    u = f*A[0]/(dh*A[2])+H\n",
    "    v = f*A[1]/(dv*A[2])+H\n",
    "    if u < -H or u > H*3 or v < -H or v > H*3:\n",
    "      continue\n",
    "    match0 = StarMatch(name, -1, v, u) # 这里uv交换一个位置，因为在图像中，x轴是v轴，y轴是u轴\n",
    "    match_ls.append(match0)\n",
    "  # match_ls, u_range, v_range = uv_reduce(match_ls, H)\n",
    "  for index, uv_true in uv_dict.items():\n",
    "    u,v = uv_true\n",
    "    distance_ls = []\n",
    "    for match0 in match_ls:\n",
    "      distance_ls.append(np.linalg.norm(np.array([u,v])-np.array([match0.u, match0.v])))\n",
    "    min_distance = min(distance_ls)\n",
    "    # print(min_distance,distance_ls.index(min_distance),index)\n",
    "    match_ls[distance_ls.index(min_distance)].index = index\n",
    "  for match0 in match_ls:\n",
    "    if match0.index == -1:\n",
    "      continue\n",
    "    star_dict[match0.index] = match0.name\n",
    " \n",
    "  return star_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "uv_dict_ls = []\n",
    "for time0 in range(50,100):\n",
    "  print(time0)\n",
    "  uv_dict = {}\n",
    "  for index, row in star_uv.iterrows():\n",
    "    if row[0] == time_ls[time0]:\n",
    "      index = int(row[3])\n",
    "      uv_dict[index] = [row[1], row[2]]\n",
    "  sensor_q = sensor[time0].q\n",
    "  # sensor_pos_est = sensor[time0].position_a + np.random.normal(0, 0.1, 3) # 加噪声\n",
    "  sensor_pos_est = sensor[time0].position_a\n",
    "  star_data = []\n",
    "  star_dict = star_match(uv_dict, star, sensor_q, sensor_pos_est)\n",
    "  uv_dict_ls.append(star_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 Star-61468 50\n",
      "19 Star-61789 50\n",
      "17 Star-62683 34\n",
      "38 Star-62867 50\n",
      "29 Star-62896 50\n",
      "43 Star-63724 28\n",
      "41 Star-63945 50\n",
      "44 Star-64004 50\n",
      "2 Star-64166 50\n",
      "28 Star-64408 50\n",
      "12 Star-64803 50\n",
      "4 Star-64962 50\n",
      "33 Star-65936 50\n",
      "21 Star-67153 50\n",
      "22 Star-67244 50\n",
      "37 Star-68245 2\n",
      "37 Star-67464 48\n",
      "46 Star-68002 50\n",
      "40 Star-68523 29\n",
      "40 Star-68282 21\n",
      "7 Star-68895 50\n",
      "32 Star-68933 50\n",
      "39 Star-70300 3\n",
      "39 Star-71352 47\n",
      "24 Star-70753 50\n",
      "30 Star-72571 50\n",
      "42 Star-63724 22\n",
      "15 Star-62683 16\n",
      "13 Star-67786 14\n",
      "34 Star-67464 2\n",
      "{36: 'Star-61468', 19: 'Star-61789', 17: 'Star-62683', 38: 'Star-62867', 29: 'Star-62896', 43: 'Star-63724', 41: 'Star-63945', 44: 'Star-64004', 2: 'Star-64166', 28: 'Star-64408', 12: 'Star-64803', 4: 'Star-64962', 33: 'Star-65936', 21: 'Star-67153', 22: 'Star-67244', 37: 'Star-67464', 46: 'Star-68002', 40: 'Star-68523', 7: 'Star-68895', 32: 'Star-68933', 39: 'Star-71352', 24: 'Star-70753', 30: 'Star-72571', 42: 'Star-63724', 15: 'Star-62683', 13: 'Star-67786', 34: 'Star-67464'}\n"
     ]
    }
   ],
   "source": [
    "final_dict = {}\n",
    "uv_dict = {}\n",
    "for star_dict in uv_dict_ls:\n",
    "  for index, name in star_dict.items():\n",
    "    if index in final_dict:\n",
    "      final_dict[index].append(name)\n",
    "    else:\n",
    "      final_dict[index] = [name]\n",
    "for index, name in final_dict.items():\n",
    "  unique_name = list(set(name))\n",
    "  frequency=[]\n",
    "  for i in unique_name:\n",
    "    frequency.append(name.count(i))\n",
    "    print(index, i, name.count(i))\n",
    "  uv_dict[index] = unique_name[frequency.index(max(frequency))]\n",
    "print(uv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         time        name  target_index            u  \\\n",
      "0     2023-04-25 16:00:05.000  Star-64166             2   196.285714   \n",
      "1     2023-04-25 16:00:05.000  Star-64962             4   203.714286   \n",
      "2     2023-04-25 16:00:05.000  Star-68895             7   324.000000   \n",
      "3     2023-04-25 16:00:05.000  Star-64803            12   499.000000   \n",
      "4     2023-04-25 16:00:05.000  Star-67786            13   525.714286   \n",
      "...                       ...         ...           ...          ...   \n",
      "20862 2023-04-25 16:01:39.900  Star-68933            32  1072.500000   \n",
      "20863 2023-04-25 16:01:39.900  Star-67464            34  1113.285714   \n",
      "20864 2023-04-25 16:01:39.900  Star-65936            33  1112.875000   \n",
      "20865 2023-04-25 16:01:39.900  Star-67464            37  1196.500000   \n",
      "20866 2023-04-25 16:01:39.900  Star-71352            39  1331.285714   \n",
      "\n",
      "                v         x         y         z  \n",
      "0      910.000000 -0.878264 -0.272935 -0.392631  \n",
      "1      547.000000 -0.865354 -0.310368 -0.393489  \n",
      "2      437.714286 -0.761076 -0.468093 -0.449058  \n",
      "3      801.714286 -0.805051 -0.280690 -0.522595  \n",
      "4      587.000000 -0.747261 -0.402395 -0.528848  \n",
      "...           ...       ...       ...       ...  \n",
      "20862  452.000000 -0.685296 -0.422693 -0.593044  \n",
      "20863  668.000000 -0.663147 -0.343389 -0.665072  \n",
      "20864  803.125000 -0.712483 -0.298929 -0.634830  \n",
      "20865  688.500000 -0.663147 -0.343389 -0.665072  \n",
      "20866  481.000000 -0.577100 -0.465270 -0.671178  \n",
      "\n",
      "[20867 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "columns=['time','name','target_index','u','v','x','y','z']\n",
    "visible_star = []\n",
    "for index, row in star_uv.iterrows():\n",
    "  if row[3] in uv_dict:\n",
    "    name = uv_dict[row[3]]\n",
    "    time = row[0]\n",
    "    target_index = row[3]\n",
    "    x,y,z = star[star_name_list.index(name)].position\n",
    "    u,v = row[1],row[2]\n",
    "    visible_star.append({'time':time,'name':name,'target_index':target_index,'u':u,'v':v,'x':x,'y':y,'z':z})\n",
    "visible_star = pd.DataFrame(visible_star, columns=columns)\n",
    "visible_star.to_csv('visible_star.csv',index=False)\n",
    "print(visible_star)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchcly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
